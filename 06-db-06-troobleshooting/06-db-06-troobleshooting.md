# Домашнее задание к занятию 6. «Troubleshooting» Потапов Василий

## Задача 1

Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).

Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD-операция в MongoDB и её 
нужно прервать. 

Вы как инженер поддержки решили произвести эту операцию:

- напишите список операций, которые вы будете производить для остановки запроса пользователя;
- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB.

## Ответ 1

CRUD-операции в MongoDB относятся к основным операциям, которые можно выполнять с данными в базе данных MongoDB. Акроним CRUD означает: Create, Read, Update, Delete.

Чтобы остановки долгой операции можно выполнить следующие шаги:

#### 1. Выявление долгой операции:

Проверить журналы MongoDB или мониторинговые инструменты, чтобы убедиться, что запрос действительно занимает длительное время. Уточнить у пользователя, какая операция выполняется (create, read, update, delete), и на каком ресурсе (коллекция, база данных).

#### 2. Остановка запроса:

Воспользоваться методами мониторинга и управления MongoDB, такими как db.currentOp(), чтобы найти долгую операцию и прервать её. Выполнить следующие команды в оболочке MongoDB:

```sql
db.currentOp(true).inprog.forEach(function(op) {
    if (op.secs_running > 180) { // Если операция выполняется более 3 минут
        db.killOp(op.opid); // Прервать операцию
    }
});
```

Использовать административные инструменты MongoDB, такие как MongoDB Compass, для управления сеансами и запросами.

#### 3. Решение проблемы с долгими запросами:

MongoDB содержит профилировщик базы данных, который оценивает производительность каждой операции с базой данных. С помощью профилировщика мы можем определить запросы, которые выполняются медленнее, чем должны, и на основе этих данных определять, когда нам необходим индекс.

## Задача 2

Перед выполнением задания познакомьтесь с документацией по [Redis latency troobleshooting](https://redis.io/topics/latency).

Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. 
Причём отношение количества записанных key-value-значений к количеству истёкших значений есть величина постоянная и
увеличивается пропорционально количеству реплик сервиса. 

При масштабировании сервиса до N реплик вы увидели, что:

- сначала происходит рост отношения записанных значений к истекшим,
- Redis блокирует операции записи.

Как вы думаете, в чём может быть проблема?

## Ответ 2

Вероятно, проблема связана с тем, что Redis блокирует операции записи из-за перегрузки операций и исчерпания ресурсов при увеличении количества реплик сервиса.

#### Причины этого могут быть следующими:

Рост "новых" пар ключ-значение по отношению к тем, которые должны быть очищены говорит о том, что растет размер хранилища, а значит ресурс памяти заканчивается. Блокировка на запись, скорее свего, говорит о том, то выделенная память закончилась.

#### Для решения проблемы можно применить следующие подходы:

- Оптимизировать запросы к Redis для уменьшения нагрузки на систему.

- Увеличить ресурсы сервера Redis (память, CPU) для обработки большего объема операций.

- Рассмотреть возможность разделения данных и операций на несколько экземпляров Redis (шардинг) для равномерного распределения нагрузки.

- Использовать асинхронные операции записи для уменьшения блокировок и увеличения пропускной способности системы.

- Оценить возможность использования других решений хранения данных или кэширования.

## Задача 3

Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей в таблицах базы
пользователи начали жаловаться на ошибки вида:
```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```

Как вы думаете, почему это начало происходить и как локализовать проблему?

Какие пути решения этой проблемы вы можете предложить?

## Ответ 3

Чаще всего данная ситуация возникает, когда происходит выборка очень большого количества данных, что очевидно, т.к. проблема стала возникать не сразу, а при росте количества записей.
Документация рекомендует нам увеличить настройку net_read_timeout с дефолтных 30 до 60 секунд, но делать это стоит только после того, как закончились пути оптимиация запроса с помощью индексов и других средств БД.

## Задача 4

Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с 
большим объёмом данных лучше, чем MySQL.

После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:

`postmaster invoked oom-killer`

Как вы думаете, что происходит?

Как бы вы решили эту проблему?

## Ответ 4

Данная ошибка говорит о том, что закончилась выделенная память. Скорее всего, объем данных все еще велик.
Если нужен именно этот объем данных, то можно попробовать выгружать не все данные целиком, а пачками (batch) меньшего размера.
